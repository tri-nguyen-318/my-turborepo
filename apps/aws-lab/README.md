# AWS Learning Lab

Learn AWS services hands-on using **LocalStack** â€” a free local AWS emulator running in Docker. No AWS account needed.

## Prerequisites

- Docker & Docker Compose installed
- Node.js >= 18
- Yarn

## Quick Start

```bash
# 1. Start LocalStack
docker compose up localstack -d

# 2. Verify it's running
curl http://localhost:4566/_localstack/health

# 3. Go to the lab
cd apps/aws-lab

# 4. Run any lab
yarn s3
yarn dynamodb
yarn sqs
yarn sns
yarn lambda
```

## Useful Commands

```bash
# Check LocalStack status
docker compose ps localstack

# View LocalStack logs
docker compose logs localstack -f

# Stop LocalStack
docker compose down localstack

# List S3 buckets (while a lab is running, before cleanup)
aws --endpoint-url http://localhost:4566 --region us-east-1 s3 ls

# List DynamoDB tables
aws --endpoint-url http://localhost:4566 --region us-east-1 dynamodb list-tables

# List SQS queues
aws --endpoint-url http://localhost:4566 --region us-east-1 sqs list-queues
```

---

## Lab 01 â€” S3 (Simple Storage Service)

**What is S3?** Object storage in the cloud â€” like a giant file system for any type of data.

**Run:** `yarn s3`

**What it does:**

| Step | Operation | What you'll see |
|------|-----------|-----------------|
| 1 | Create a bucket | `âœ… Bucket "my-learning-bucket" created` |
| 2 | Upload 3 files (text + JSON) | `âœ… Uploaded hello.txt` |
| 3 | Download and read a file | `ğŸ“„ Content of hello.txt: "Hello from S3!..."` |
| 4 | List objects with prefix filtering | Files listed with size and timestamp |
| 5 | Generate a presigned URL | A temporary signed URL printed to console |
| 6 | Delete everything | All objects and the bucket removed |

**Key concepts learned:**
- **Bucket** â€” a container for files (must be globally unique)
- **Key** â€” the "path" to a file inside a bucket (e.g. `data/users.json`)
- **Presigned URL** â€” a temporary link to access a private file without credentials
- **Prefix filtering** â€” simulating folders by filtering keys that start with `data/`

---

## Lab 02 â€” DynamoDB

**What is DynamoDB?** A fully managed NoSQL key-value database, designed for massive scale.

**Run:** `yarn dynamodb`

**What it does:**

| Step | Operation | What you'll see |
|------|-----------|-----------------|
| 1 | Create a table with partition + sort key | `âœ… Table "Users" is ACTIVE` |
| 2 | Insert 4 user items | `âœ… Inserted: Tri (tri@example.com)` |
| 3 | Get a single item by key | Full item printed with all attributes |
| 4 | Update an item's attributes | Updated item with new age and role |
| 5 | Query by partition key | All items for `user-1` (2 results) |
| 6 | Scan with filter | All users with role `developer` |
| 7 | Delete an item | `ğŸ—‘ï¸ Deleted user-3` |
| 8 | Delete the table | Table removed |

**Key concepts learned:**
- **Partition Key (PK)** â€” the main key to identify items (like a primary key)
- **Sort Key (SK)** â€” optional second key for ordering and range queries
- **Query vs Scan** â€” Query is fast (uses PK), Scan reads the whole table (expensive!)
- **UpdateExpression** â€” a mini-language to modify specific fields without replacing the whole item
- **DocumentClient** â€” a wrapper that lets you use plain JS objects instead of DynamoDB's verbose format

---

## Lab 03 â€” SQS (Simple Queue Service)

**What is SQS?** A message queue that decouples producers and consumers. One service sends messages, another processes them later.

**Run:** `yarn sqs`

**What it does:**

| Step | Operation | What you'll see |
|------|-----------|-----------------|
| 1 | Create a queue | `âœ… Queue created: http://...` |
| 2 | Send a single message | `âœ… Message sent! ID: ...` |
| 3 | Send a batch of 3 messages | `âœ… Batch of 3 messages sent` |
| 4 | Receive and inspect messages | Message body, ID, and receipt handle printed |
| 5 | Delete messages after processing | `ğŸ—‘ï¸ Deleted message: ...` |
| 6 | Consumer loop (poll until empty) | `âœ… Processed: ORDER_CREATED (ORD-002)` |
| 7 | Delete the queue | Queue removed |

**Key concepts learned:**
- **Producer/Consumer pattern** â€” one service sends, another reads and processes
- **Visibility Timeout** â€” after reading, a message is hidden from other consumers; if not deleted, it reappears
- **Long Polling** â€” `WaitTimeSeconds` makes the consumer wait for messages instead of returning empty immediately
- **Delete after processing** â€” you must explicitly delete messages; this ensures at-least-once delivery
- **Batch operations** â€” send up to 10 messages in a single API call for efficiency

---

## Lab 04 â€” SNS (Simple Notification Service)

**What is SNS?** A pub/sub service. A publisher sends one message to a "topic", and SNS delivers copies to all subscribers.

**Run:** `yarn sns`

**What it does:**

| Step | Operation | What you'll see |
|------|-----------|-----------------|
| 1 | Create an SNS topic | `âœ… Topic created: arn:aws:sns:...` |
| 2 | Create 2 SQS queues as subscribers | `âœ… Created queue: email-notifications` |
| 3 | Subscribe both queues to the topic | `âœ… Email queue subscribed` |
| 4 | Publish 2 events to the topic | `âœ… Published ORDER_CREATED event` |
| 5 | Read from both queues â€” same messages! | Both queues show the same order events |
| 6 | Cleanup | Topic, subscriptions, and queues deleted |

**Key concepts learned:**
- **Fan-out pattern** â€” 1 message â†’ N subscribers (e.g., one order event triggers email + inventory + analytics)
- **SNS vs SQS** â€” SNS is push-based (one-to-many), SQS is pull-based (one-to-one)
- **SNS + SQS together** â€” the most common pattern: SNS fans out to multiple SQS queues, each processed independently
- **Topic/Subscription model** â€” publishers don't know about subscribers; adding a new consumer requires zero code changes to the publisher

---

## Lab 05 â€” Lambda

**What is Lambda?** Serverless compute â€” upload your code, AWS runs it on demand. No servers to manage.

**Run:** `yarn lambda`

**What it does:**

| Step | Operation | What you'll see |
|------|-----------|-----------------|
| 1 | Create a function from code | `âœ… Function "my-hello-function" created` |
| 2 | Get function details | Runtime, memory, timeout, handler info |
| 3 | Invoke synchronously (wait for result) | `ğŸ“„ Response: { message: "Hello, Tri!..." }` |
| 4 | Invoke with different payloads | 3 different inputs â†’ 3 different outputs |
| 5 | List all functions | Functions listed with runtime and memory |
| 6 | Invoke asynchronously (fire & forget) | `ğŸ“Š Status: 202 (accepted)` |
| 7 | Delete the function | Function removed |

**Key concepts learned:**
- **Handler** â€” the entry point function (`index.handler` = `index.js` file, `handler` export)
- **Synchronous vs Async invocation** â€” `RequestResponse` waits for result; `Event` returns immediately
- **Cold start** â€” first invocation is slower because Lambda needs to initialize a container
- **Event-driven** â€” in real AWS, Lambda is triggered by S3 uploads, SQS messages, API Gateway requests, scheduled cron, etc.
- **Pay-per-use** â€” you only pay for the time your code runs (no idle server costs)

---

## Learning Path

Run the labs in order â€” each builds on concepts from the previous one:

```
01-s3        â†’ Storage basics (where your files live)
02-dynamodb  â†’ Database basics (where your data lives)
03-sqs       â†’ Messaging basics (how services talk to each other)
04-sns       â†’ Pub/Sub + Fan-out (one event â†’ many consumers, uses SQS from lab 03)
05-lambda    â†’ Serverless compute (code that runs without servers)
```

## Troubleshooting

**LocalStack won't start:**
```bash
docker compose logs localstack  # Check logs for errors
docker compose down && docker compose up localstack -d  # Restart
```

**"Connection refused" errors:**
- Make sure LocalStack is running: `docker compose ps localstack`
- Check the health endpoint: `curl http://localhost:4566/_localstack/health`

**Port 4566 already in use:**
```bash
lsof -i :4566  # Find what's using the port
```
